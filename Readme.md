# TOON 

This repo demonstrates TOON (Token-Oriented Object Notation) implementation and converting JSON to TOON and back, and benchmarking token counts for LLM prompt cost comparisons.

We use:
- `convert.py` â€” convert JSON â†’ TOON and TOON â†’ JSON (uses `toon_format.encode` / `decode`)
- `benchmark.py` â€” count tokens for JSON vs TOON (uses `toon_format.count_tokens` or `tiktoken` fallback)

**Result from our benchmark:**<br>
--- TOON vs JSON token benchmark ---<br>
Model: gpt-4o-mini<br>
JSON length (chars): 4076<br>
TOON length (chars): 859<br>
JSON tokens: 1048<br>
TOON tokens: 369<br>
Reduction: 64.79%<br>


## ğŸ“‚ Project Structure

â”œâ”€â”€ convert.py          
â”œâ”€â”€ benchmark.py       
â”œâ”€â”€ sample.json         
â”œâ”€â”€ sample.toon         
â”œâ”€â”€ requirements.txt   
â””â”€â”€ README.md

## ğŸ”§ Installation:

git clone https://github.com/Susma261/TOON.git <br>
cd TOON

- `python -m venv venv`
- `source venv/bin/activate`
- `venv\Scripts\activate`         

- `pip install -r requirements.txt`

*If toon_format is not installable through pip, install the official repo:*<br>
- `https://github.com/toon-format/toon-python.git`

## ğŸ“ Sample Dataset:

- `sample.json` contains 30 employee records from a fictional company<br>
- `sample.toon` is a compact TOON representation

## ğŸ“¬ Contact:
LinkedIn: https://www.linkedin.com/in/susma-r/









